{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GSgDIquAkOC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8dAtc4IBy5g"
   },
   "outputs": [],
   "source": [
    "df_a = pd.read_csv('TE_a.csv')\n",
    "df_b = pd.read_csv('TE_b.csv')\n",
    "df_c = pd.read_csv('TE_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1661522374051,
     "user": {
      "displayName": "Shivam Mathur",
      "userId": "13996464205483377357"
     },
     "user_tz": 420
    },
    "id": "C4iFlZMmCU0H",
    "outputId": "3e5f67bb-07d6-4efd-9992-e1158790f015"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y     212\n",
       "n     157\n",
       "uk     80\n",
       "py     49\n",
       "pn     29\n",
       "Name: gold_adj, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b['gold_adj'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5Sn-zspC0OA"
   },
   "outputs": [],
   "source": [
    "def majority(df):\n",
    "  df['predict'] = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1661522886511,
     "user": {
      "displayName": "Shivam Mathur",
      "userId": "13996464205483377357"
     },
     "user_tz": 420
    },
    "id": "0r_1daXADFiF",
    "outputId": "5166060f-5ea4-423f-8232-1ec895f3bc45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.00      0.00      0.00       155\n",
      "          pn       0.00      0.00      0.00        31\n",
      "          py       0.00      0.00      0.00        69\n",
      "          uk       0.00      0.00      0.00       109\n",
      "           y       0.39      1.00      0.56       236\n",
      "\n",
      "    accuracy                           0.39       600\n",
      "   macro avg       0.08      0.20      0.11       600\n",
      "weighted avg       0.15      0.39      0.22       600\n",
      "\n",
      "==============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.00      0.00      0.00       157\n",
      "          pn       0.00      0.00      0.00        29\n",
      "          py       0.00      0.00      0.00        49\n",
      "          uk       0.00      0.00      0.00        80\n",
      "           y       0.40      1.00      0.57       212\n",
      "\n",
      "    accuracy                           0.40       527\n",
      "   macro avg       0.08      0.20      0.11       527\n",
      "weighted avg       0.16      0.40      0.23       527\n",
      "\n",
      "==============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.00      0.00      0.00       177\n",
      "          pn       0.00      0.00      0.00        32\n",
      "          py       0.00      0.00      0.00        51\n",
      "          uk       0.00      0.00      0.00        96\n",
      "           y       0.41      1.00      0.58       244\n",
      "\n",
      "    accuracy                           0.41       600\n",
      "   macro avg       0.08      0.20      0.12       600\n",
      "weighted avg       0.17      0.41      0.24       600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "majority(df_a)\n",
    "majority(df_b)\n",
    "majority(df_c)\n",
    "\n",
    "print('majority class')\n",
    "print(classification_report(y_true = df_a['gold_adj'], y_pred = df_a['predict']))\n",
    "print('==============================================')\n",
    "print(classification_report(y_true = df_b['gold_adj'], y_pred = df_b['predict']))\n",
    "print('==============================================')\n",
    "print(classification_report(y_true = df_c['gold_adj'], y_pred = df_c['predict']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qti3vqN7fcBT"
   },
   "outputs": [],
   "source": [
    "df_a['predict'].to_csv('A_majority.csv')\n",
    "df_b['predict'].to_csv('B_majority.csv')\n",
    "df_c['predict'].to_csv('C_majority.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6MY38fJx0LS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyHfn_tcA7DR"
   },
   "outputs": [],
   "source": [
    "# Keyword baseline\n",
    "yes_keyword_regex = \"(yes|yea|yeah|sure|right|you bet|of course|certainly|definitely|uh huh)(\\W*?)\"\n",
    "no_keyword_regex = \"(no|nope|no way|never|n't)(\\W*?)\"\n",
    "probably_keyword_regex = \"(maybe|may|sometimes|can|perhaps|if)(\\W*?)\"\n",
    "\n",
    "def classify(sent):\n",
    "  predict = []\n",
    "\n",
    "  if re.findall(yes_keyword_regex, str(sent)):\n",
    "    if re.findall(probably_keyword_regex, str(sent)):\n",
    "      predict.append('py')\n",
    "    else:\n",
    "      predict.append('y')\n",
    "\n",
    "  if re.findall(no_keyword_regex, str(sent)):\n",
    "    if re.findall(probably_keyword_regex, str(sent)):\n",
    "      predict.append('pn')\n",
    "    else: \n",
    "      predict.append('n')\n",
    "  # print(predict)\n",
    "  if len(predict) == 0:\n",
    "    return 'uk'\n",
    "  else:\n",
    "    return random.choice(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfVJCMZ5IWIa"
   },
   "outputs": [],
   "source": [
    "df_a['predict'] = df_a['Reply_tweet'].apply(lambda x: classify(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1661523518462,
     "user": {
      "displayName": "Shivam Mathur",
      "userId": "13996464205483377357"
     },
     "user_tz": 420
    },
    "id": "XRfEnTQkhLpD",
    "outputId": "7badf7d7-8d5e-4de5-bb26-2fa3c9a6ceed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uk    268\n",
       "n     179\n",
       "y      81\n",
       "pn     51\n",
       "py     21\n",
       "Name: predict, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a['predict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1661523543263,
     "user": {
      "displayName": "Shivam Mathur",
      "userId": "13996464205483377357"
     },
     "user_tz": 420
    },
    "id": "W5Fi9yl8FvKI",
    "outputId": "981ba15a-0caa-40fa-e215-308cb7795750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword baseline\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.45      0.52      0.48       155\n",
      "          pn       0.12      0.19      0.15        31\n",
      "          py       0.26      0.09      0.13        69\n",
      "          uk       0.24      0.60      0.34       109\n",
      "           y       0.79      0.27      0.40       236\n",
      "\n",
      "    accuracy                           0.37       600\n",
      "   macro avg       0.37      0.33      0.30       600\n",
      "weighted avg       0.51      0.37      0.37       600\n",
      "\n",
      "==============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.46      0.45      0.45       157\n",
      "          pn       0.13      0.21      0.16        29\n",
      "          py       0.27      0.14      0.19        49\n",
      "          uk       0.19      0.56      0.29        80\n",
      "           y       0.74      0.23      0.35       212\n",
      "\n",
      "    accuracy                           0.34       527\n",
      "   macro avg       0.36      0.32      0.29       527\n",
      "weighted avg       0.49      0.34      0.34       527\n",
      "\n",
      "==============================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.49      0.49      0.49       177\n",
      "          pn       0.19      0.34      0.25        32\n",
      "          py       0.30      0.14      0.19        51\n",
      "          uk       0.23      0.66      0.35        96\n",
      "           y       0.81      0.25      0.38       244\n",
      "\n",
      "    accuracy                           0.38       600\n",
      "   macro avg       0.41      0.38      0.33       600\n",
      "weighted avg       0.55      0.38      0.39       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_a['predict'] = df_a['Reply_tweet'].apply(lambda x: classify(x))\n",
    "df_b['predict'] = df_b['Reply_tweet'].apply(lambda x: classify(x))\n",
    "df_c['predict'] = df_c['Reply_tweet'].apply(lambda x: classify(x))\n",
    "\n",
    "\n",
    "print('keyword baseline')\n",
    "print(classification_report(y_true = df_a['gold_adj'], y_pred = df_a['predict']))\n",
    "print('==============================================')\n",
    "print(classification_report(y_true = df_b['gold_adj'], y_pred = df_b['predict']))\n",
    "print('==============================================')\n",
    "print(classification_report(y_true = df_c['gold_adj'], y_pred = df_c['predict']))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMk3FVply2bCXQZYwmyzr8y",
   "mount_file_id": "1qo8_6K8NsupDoRv1qqLI1_o7biNmlGsR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
